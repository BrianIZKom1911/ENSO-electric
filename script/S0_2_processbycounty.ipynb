{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the psv files one by one for the following tasks:\n",
    "# I) Station to County\n",
    "# 1) Read population data from the csv file\n",
    "# 2) Get station-county mapping from county_station_list\n",
    "# 3) Identify files from database folder for all counties with one or more stations\n",
    "\n",
    "# 4) Loop over all counties:\n",
    "# 4-1) Read the station files for each county \n",
    "# 4-2) Keep only needed columns: ['Station_ID', datetime, 'Latitude', 'Longitude']+\n",
    "# ['temperature', 'dew_point_temperature', 'station_level_pressure', 'wind_speed', 'precipitation', 'relative_humidity', 'wet_bulb_temperature', 'sky_cover_1']\n",
    "# 4-3) Round datetime to the nearest hour. Then, average weather variables for each county by datetime\n",
    "# 4-4) Give the county name from the mapping. Merge with population by year-county\n",
    "# 4-5) Save county data to a new csv file (a. county)\n",
    "\n",
    "# II.\n",
    "# 1) Calculate population-weighted averages of the weather variables for the state \n",
    "# 2) Save (b. WA state)\n",
    "# 3) Prepare for the next step: Estimate temp density every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "md = 'D:/OneDrive - University of Missouri/transfer_desktop/MU/2025spring_submit1'\n",
    "cols_w = ['temperature', 'dew_point_temperature', 'station_level_pressure', 'wind_speed', 'precipitation', \n",
    "          'relative_humidity', 'wet_bulb_temperature', 'sky_cover_1']\n",
    "## In the current study, only temperature is used for analysis. However, other met variables might be used for their correlation\n",
    "#with ENSO in future studies\n",
    "cols_keep = ['Station_ID', 'Station_name', 'Year', 'Month', 'Day', 'Hour', 'Minute', 'Latitude', 'Longitude'] + cols_w\n",
    "cols_w[(len(cols_w)-1)] = 'skycover' # used for averaging after numerizing sky_cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert sky_cover to numerical values\n",
    "def skycover_numerize(x):\n",
    "    if x == 'CLR:00':\n",
    "        return 0\n",
    "    elif x == 'FEW:01':\n",
    "        return 1/8\n",
    "    elif x == 'FEW:02':\n",
    "        return 2/8\n",
    "    elif x == 'SCT:03':\n",
    "        return 3/8\n",
    "    elif x == 'SCT:04':\n",
    "        return 4/8\n",
    "    elif x == 'BKN:05':\n",
    "        return 5/8\n",
    "    elif x == 'BKN:06':\n",
    "        return 6/8\n",
    "    elif x == 'BKN:07':\n",
    "        return 7/8\n",
    "    elif x == 'OVC:08':\n",
    "        return 1\n",
    "    elif x == 'VV:09': # sky obscured\n",
    "        return 1\n",
    "    elif x == 'X:10':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import population data\n",
    "dt_pop = pd.read_csv(os.path.join(md, 'data_clean', 'population_1960_2024.csv'), usecols=['County', 'Year', 'Population'])\n",
    "dt_pop = dt_pop.drop_duplicates(subset=['County', 'Year'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inpath = 'D:/OneDrive - University of Missouri/transfer_desktop/MU/database/GHCNh_WA'\n",
    "inpath = os.path.join(md, 'data_raw', 'GHCNh_WA')\n",
    "outpath = os.path.join(md, 'data_intermediate', 'GHCNh_counties25') # store the county data here\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath) # create parent directory too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import weather data - Prepare\n",
    "psv_filepaths = [os.path.join(inpath, file) for file in os.listdir(inpath) if file.endswith('.psv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get station-county mapping from the list\n",
    "df_id = pd.read_excel(os.path.join(md, 'data_document', 'county_station_list.xlsx'), sheet_name='GHCNh', usecols=[0, 3], header=0, nrows=27)\n",
    "\n",
    "df_id = df_id.rename(columns={'ID': 'Station_ID'})\n",
    "df_id[['County', 'Station_ID']] = df_id[['County', 'Station_ID']].apply(lambda x: x.str.strip())\n",
    "## remove leading and trailing spaces\n",
    "df_id = df_id.drop_duplicates(subset='Station_ID', keep='first')\n",
    "## delete the latter county(s) that share the same station with another county; here: Douglas - USW00094239\n",
    "\n",
    "# Identify files for counties with one or more stations\n",
    "county_stations = df_id.copy()\n",
    "county_stations['filepath'] = county_stations['Station_ID'].apply(lambda x: [path for path in psv_filepaths if x in path])\n",
    "county_stations = county_stations.groupby('County').agg(lambda x: x.explode().tolist()).reset_index()\n",
    "## make stations and filepaths to a list for each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop: Handle all counties at once\n",
    "for i in np.arange(county_stations.shape[0]):\n",
    "    county = county_stations.loc[i, 'County']\n",
    "    paths = county_stations.loc[i, 'filepath']\n",
    "    dt_cty = pd.concat([pd.read_csv(path, sep='|', usecols=cols_keep, low_memory=False) for path in paths], axis=0, ignore_index=True)\n",
    "    dt_cty = dt_cty[(dt_cty['Year'] >= 2000) & (dt_cty['Year'] <= 2024)]\n",
    "\n",
    "    # Clean weather data\n",
    "    dt_cty['skycover'] = dt_cty['sky_cover_1'].apply(skycover_numerize) # numerize sky_cover\n",
    "    dt_cty['precipitation'] = dt_cty['precipitation'].apply(lambda x: 0 if np.isnan(x) else x) # replace missing precipitation with 0\n",
    "    dt_cty['relative_humidity'] = dt_cty['relative_humidity'].apply(lambda x: 109.9876 if x > 110 else x) # relative humidity can't be > 110\n",
    "    dt_cty['dew_point_temperature'] = dt_cty['dew_point_temperature'].apply(lambda x: 20.9876 if x > 21 else x) # dew_point_temperature can hardly be > 21\n",
    "    dt_cty['wet_bulb_temperature'] = dt_cty['wet_bulb_temperature'].apply(lambda x: 35.9876 if x > 36 else x) # wet_bulb_temperature can hardly be > 36\n",
    "    dt_cty['temperature'] = dt_cty['temperature'].apply(lambda x: 47.9876 if x > 48 else x) # temperature can't be higher than 48.9\n",
    "    # Average weather variables by datetime\n",
    "    dt_cty['datetime'] = pd.to_datetime(dt_cty[['Year', 'Month', 'Day', 'Hour', 'Minute']]).dt.round('h')\n",
    "    ## round the datetime to the nearest hour # previously: dt.floor.('h')\n",
    "    dt_cty = dt_cty.groupby(['datetime'])[cols_w].mean().reset_index()\n",
    "    dt_cty = dt_cty.dropna(subset=['temperature']) # drop rows with missing temperature because all models need temperature\n",
    "    \n",
    "    # Merge with population\n",
    "    dt_cty['County'] = county\n",
    "    dt_cty['Year'] = dt_cty['datetime'].dt.year\n",
    "    dt_cty = dt_cty.merge(dt_pop, on=['Year', 'County'], how='left')\n",
    "    dt_cty.to_csv(os.path.join(outpath, f'{county}_2000-2024.csv'), index=False)\n",
    "    print(county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate population-weighted average\n",
    "def weighted_avg(df, xcols, w):\n",
    "    result = {}\n",
    "\n",
    "    for col in xcols:\n",
    "        valid_mask = df[col].notna()  # Mask for non-missing values in this column\n",
    "        wt_sum = (df[col] * df[w]).where(valid_mask, 0)  # Multiply only valid values\n",
    "        sumofwts = df[w].where(valid_mask, 0)  # Sum only valid weights\n",
    "\n",
    "        group_wt_sum = wt_sum.groupby(df['datetime']).sum()\n",
    "        group_sumofwts = sumofwts.groupby(df['datetime']).sum()\n",
    "\n",
    "        result[col] = group_wt_sum / group_sumofwts  # Compute weighted avg\n",
    "\n",
    "    return pd.DataFrame(result).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_files = glob.glob(os.path.join(outpath, '*.csv'))\n",
    "dt_counties = pd.concat([pd.read_csv(file) for file in county_files], ignore_index=True)\n",
    "dt_counties['datetime'] = pd.to_datetime(dt_counties['datetime'])\n",
    "wt_avgs = weighted_avg(dt_counties, cols_w, 'Population')\n",
    "wt_avgs.to_csv(os.path.join(md, 'data_clean', 'WA_weather_1990-2024.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for regression - Estimate kernel density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def kde_month_t(df):\n",
    "    df['f_r'] = None\n",
    "    for month in df['yyyymm'].unique():\n",
    "        month_data = df.loc[df['yyyymm']==month, 'temperature'].values\n",
    "        \n",
    "        if len(month_data) < 200:\n",
    "            density_est = np.nan\n",
    "        else:\n",
    "            kde = gaussian_kde(month_data)\n",
    "            density_est = kde(month_data)\n",
    "        \n",
    "        df.loc[df['yyyymm']==month, 'f_r'] = density_est\n",
    "    return df\n",
    "\n",
    "def get_density(df):\n",
    "    # Add year-month variable and compute density\n",
    "    df['datetime00'] = pd.to_datetime(df['datetime00'])\n",
    "    df['Year'] = pd.to_datetime(df['datetime00']).dt.year\n",
    "    df['Month'] = pd.to_datetime(df['datetime00']).dt.month\n",
    "    df['yyyymm'] = df['Year'].astype(str) + '-' + df['Month'].astype(str).str.zfill(2)\n",
    "    return kde_month_t(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_wa = get_density(wt_avgs)\n",
    "dt_wa.to_csv(os.path.join(md, 'data_clean', 'WA_wt_density.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
